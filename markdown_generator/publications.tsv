pub_date	title	venue	excerpt	citation	url_slug	paper_url
2013-12-13	Narrative Fragment Creation: An Approach for Learning Narrative Knowledge	Advances in Cognitive Systems	We propose the narrative fragment - a sequence of story events - and a method for automatically creating these fragments with narrative generation through partial order planning and analysis through n-gram modeling. The generated plans establish causal and temporal relationships, and by modeling those relationships and creating fragments, our system learns narrative knowledge.	C. Cervantes & W. Fu. (2013) Narrative Fragment Creation: An Approach for Learning Narrative Knowledge. Conference on Advances in Cognitive Systems (ACS)	cervantes_narrative	https://cmcervantes.github.io/files/cervantes_2013_narrative.pdf
2015-12-13	Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models	International Conference on Computer Vision	This paper presents Flickr30k Entities, which augments the 158k captions from Flickr30k with 244k coreference chains linking mentions of the same entities in images, as well as 276k manually annotated bounding boxes corresponding to each entity. We present experiments demonstrating the usefulness of our annotations for text-to-image reference resolution, or the task of localizing textual entity mentions in an image, and for bidirectional image-sentence retrieval.	B. Plummer, L. Wang, C. Cervantes, J. Caicedo, J. Hockenmaier, & S. Lazebnik. (2015) Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models. International Conference on Computer Vision (ICCV)	plummer_flickr30kEntities	https://cmcervantes.github.io/files/plummer_2015_flickr30kEntities.pdf
2017-01-01	Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models	International Journal of Computer Vision	This journal version of the 2015 paper of the same name adds experiments, analysis, and examples to the existing work.	B. Plummer, L. Wang, C. Cervantes, J. Caicedo, J. Hockenmaier, & S. Lazebnik. (2017) Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models. International Journal of Computer Vision (IJCV)	plummer_flickr30kEntities	https://cmcervantes.github.io/files/plummer_2017_flickr30kEntities.pdf
2017-10-22	Phrase Localization and Visual Relationship Detection with Comprehensive Image-Language Cues	International Conference on Computer Vision	This  paper  presents  a  framework  for  localization  or grounding  of  phrases  in  images  using a  large  collection of  linguistic  and  visual  cues.   We  model  the  appearance, size, and position of entity bounding boxes, adjectives that contain attribute information, and spatial relationships between pairs of entities connected by verbs or prepositions. Special attention is given to relationships between people and clothing or body part mentions, as they are useful for distinguishing individuals.	B. Plummer, A. Mallya, C. Cervantes, J. Hockenmaier, & S. Lazebnik. (2017) Phrase Localization and Visual Relationship Detection with Comprehensive Image-Language Cues. International Conference on Computer Vision (ICCV)	plummer_phrase	https://cmcervantes.github.io/files/plummer_2017_phrase.pdf
2018-02-01	Entity-Based Scene Understanding for Flickr30k and MSCOCO		We define entity-based scene understanding as the task of identifying the entities in a visual scene from multiple descriptions by a) identifying coreference and subset relations between entity mentions, and b) grounding entity mentions to image regions. We apply our models to two datasets (Flickr30K Entities v2 and MSCOCO) and show that grounding can benefit significantly from relation prediction in both cases. 	C. Cervantes, B. Plummer, S. Lazebnik, & J. Hockenmaier. (2018) Entity-Based Scene Understanding for Flickr30k and MSCOCO. Under Review / Available Upon Request	cervantes_entity	
